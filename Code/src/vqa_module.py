# -*- coding: utf-8 -*-
"""VQA_module.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13BWDYFKJaEPyweiTnwQIAfy9DD4I-yNW
"""

!pip install transformers

import os
import h5py
import json
import numpy as np
from transformers import DistilBertTokenizer, TFDistilBertModel
import cv2
from sklearn.model_selection import train_test_split

import keras as keras
from keras.models import Model
from keras import layers as layers
from keras.initializers import glorot_uniform
from tensorflow.keras import backend as K
K.set_image_data_format('channels_last')
import tensorflow as tf
from tensorflow.keras.utils import to_categorical, plot_model

import nltk
import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')
from nltk.stem.snowball import SnowballStemmer

#import dataset file
base_path = '/content/drive/MyDrive/VQA_Datasets'
image_path = base_path + '/VQA_RAD Image Folder'
output_path = base_path

with open(base_path + "/VQA_RAD Dataset Public.json", "r") as f:
    rad_json_data = json.load(f)
rad_json_data = [d for d in rad_json_data if d["answer_type"] == "CLOSED"]

print(rad_json_data[0])
print(len(rad_json_data))

import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.utils import to_categorical, Sequence
from transformers import DistilBertTokenizer
from sklearn.model_selection import train_test_split

# parameters
max_length  = 10
batch_size  = 64
image_shape = (224, 224)  # (H, W)
tokenizer   = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# precompute vocab and map to integer
vocab = sorted({q["answer"].lower() for q in rad_json_data})
wtoi  = {w: i for i, w in enumerate(vocab)}

def load_images_from_list(pixel_x, pixel_y, img_names, folder_path=image_path):
    imgs = []
    for fn in img_names:
        im = cv2.imread(f"{folder_path}/{fn}", cv2.IMREAD_GRAYSCALE)
        im = cv2.resize(im, (pixel_y, pixel_x), interpolation=cv2.INTER_AREA)
        imgs.append(im)
    # normalize and add channel dim
    imgs = np.array(imgs, dtype=np.float32) / 255.0       
    imgs = imgs[..., np.newaxis]                          
    # repeat into 3 channels
    imgs = np.repeat(imgs, 3, axis=-1)                
    return imgs


class DataGenerator(Sequence):
    def __init__(self, json_data, batch_size, shuffle=True, **kwargs):
        super().__init__(**kwargs)
        self.json_data  = json_data
        self.batch_size = batch_size
        self.shuffle    = shuffle
        self.indices    = np.arange(len(self.json_data))
        if self.shuffle:
            np.random.shuffle(self.indices)

    def __len__(self):
        return int(np.ceil(len(self.json_data) / self.batch_size))

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

    def preprocess_text(self, texts):
        # return input_ids as a NumPy array
        toks = tokenizer(
            texts,
            max_length=max_length,
            truncation=True,
            padding='max_length',
            return_tensors='tf'
        )
        return toks.input_ids.numpy(), toks.attention_mask.numpy()

    def __getitem__(self, idx):
        # pick the batch of indices
        batch_idx = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]
        batch_data = [self.json_data[i] for i in batch_idx]

        # images
        names = [d["image_name"] for d in batch_data]
        X_img = load_images_from_list(image_shape[0], image_shape[1], names)

        # questions → token IDs
        questions = [d["question"] for d in batch_data]
        X_ids, X_mask = self.preprocess_text(questions)

        # labels → one‐hot
        y_ids = np.array([wtoi[d["answer"].lower()] for d in batch_data])
        y     = to_categorical(y_ids, num_classes=len(vocab))

        return (X_ids, X_mask, X_img), y

# split and instantiate
train_json, valid_json = train_test_split(rad_json_data, test_size=0.1, random_state=42)
train_gen = DataGenerator(train_json, batch_size)
valid_gen = DataGenerator(valid_json, batch_size, shuffle=False)

# Model MFB Block
class MFBBlock(tf.keras.layers.Layer):
    def __init__(self, drop_out_rate=0.5, factor_num=10, out_dim=None, **kwargs):
        super().__init__(**kwargs)
        self.drop_out_rate = drop_out_rate
        self.factor_num    = factor_num
        self.out_dim       = out_dim

    def build(self, input_shape):
        # input_shape = [(batch, D), (batch, D)]
        D = input_shape[0][-1]
        if self.out_dim is None:
            if D % self.factor_num != 0:
                raise ValueError(f"feature dim {D} not divisible by factor_num {self.factor_num}")
            self.out_dim = D // self.factor_num
        super().build(input_shape)

    def call(self, inputs, training=None):
        x, y = inputs
        exp2 = tf.nn.dropout(x * y, rate=self.drop_out_rate) if training else x*y
        batch = tf.shape(exp2)[0]
        # reshape to (batch, out_dim, factor_num)
        exp2 = tf.reshape(exp2, (batch, self.out_dim, self.factor_num))
        sq1  = tf.reduce_mean(exp2, axis=-1)                     
        sq2  = tf.sign(sq1) * tf.sqrt(tf.abs(sq1) + 1e-12)     
        return tf.nn.l2_normalize(sq2, axis=-1)                



# Resnet model
resnet50 = tf.keras.applications.ResNet50(
        include_top=False,
        weights="imagenet",
        input_shape=(224, 224, 3),
    )

# DistilBert
distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')

# The Complete model Including resnet and distilBert
class DistilBERTWrapper(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')

    def call(self, inputs):
        input_ids, attention_mask = inputs
        return self.distilbert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state

def get_vqa_model(q_input_shape, img_input_shape, max_length, classes_n, img_feat_len=1000):
    # Question inputs
    q_input = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')
    attention_mask = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')

    # Wrap DistilBERT in the custom layer
    distilbert_layer = DistilBERTWrapper()
    distilbert_output = distilbert_layer((q_input, attention_mask))
    q_feat = tf.keras.layers.GlobalAveragePooling1D()(distilbert_output)
    q_feat = tf.keras.layers.Dense(img_feat_len, activation='relu', kernel_initializer=glorot_uniform(seed=0))(q_feat)
    q_feat = tf.keras.layers.Dropout(0.5)(q_feat)

    # Image input
    img_input = tf.keras.Input(shape=(224, 224, 3), dtype='float32', name='image')
    resnet_output = tf.keras.applications.ResNet50(include_top=False, pooling='avg')(img_input)
    img_feat = tf.keras.layers.Dense(img_feat_len, activation='relu', kernel_initializer=glorot_uniform(seed=0))(resnet_output)
    img_feat = tf.keras.layers.Dropout(0.5)(img_feat)

    # MFB Block and output
    x = MFBBlock(factor_num=10)([q_feat, img_feat])
    x = tf.keras.layers.Dense(classes_n)(x)
    x = tf.keras.layers.Activation('softmax')(x)

    model = tf.keras.Model(inputs=[q_input, attention_mask, img_input], outputs=x)
    return model

# Compile the model
vqa_model = get_vqa_model((10, 768), (1000,), max_length=max_length, classes_n=len(vocab))
vqa_model.summary()
len(vocab)

# compile & Train Model
import os
from tensorflow.keras.callbacks import ModelCheckpoint

# Define the path where you want to save the best model
best_model_path = os.path.join(output_path, "vqa_model.keras")

# Create the ModelCheckpoint callback
checkpoint = ModelCheckpoint(
    filepath=best_model_path,
    monitor='val_loss',
    save_best_only=True,
    save_weights_only=False,
    verbose=1
)

# Compile the model
vqa_model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.keras.optimizers.RMSprop(learning_rate=3e-4),
    metrics=['accuracy']
)

# Train the model with the checkpoint callback
history = vqa_model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=12,
    callbacks=[checkpoint]
)

# Show model structure
plot_model(vqa_model, show_shapes=True)

# Combine history and save model
combined_history = {}

# Access history.history directly
for key in history.history.keys(): 
    combined_history[key] = history.history[key] 

vqa_model.save(output_path + "/vqa_model.keras")

# Model eval
import matplotlib.pyplot as plt

def plot_combined_history(history):
    plt.figure(figsize=(12, 6))

    # Plot training & validation accuracy values
    plt.subplot(1, 2, 1)
    plt.plot(history['accuracy'])
    plt.plot(history['val_accuracy'])
    plt.title('Model accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history['loss'])
    plt.plot(history['val_loss'])
    plt.title('Model loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(['Train', 'Validation'], loc='upper left')

    plt.show()

# Call the function with the combined history
plot_combined_history(combined_history)