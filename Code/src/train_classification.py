# -*- coding: utf-8 -*-
"""Train_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14kyGuzpgEKX1MG0suCnhpSfhH-okSe5Q
"""

# !pip install gdown

import gdown

#replace file_ID with your actual file ID
file_id = '1-SWJ_nIgotQ11ZHapb-uqWndvzeRs80d'
output_file = 'Chest_XRay_Datasets.zip'

#Download the file
gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)

# UNzip the downloaded file
import zipfile
Unzip_file = zipfile.ZipFile('/content/Chest_XRay_Datasets.zip')
Unzip_file.extractall()

#Import Libraries
import os
import random
import time
import copy
import numpy as np
import pandas as pd
import glob
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from PIL import Image, ImageOps

#Torch Libraries
import torch
import torch.nn as nn
from torchvision import transforms
from torchvision import datasets
from torch.optim import Adam
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision.models import mobilenet_v2, densenet121, resnet18

#Checking GPU availability
torch.cuda.is_available()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

#Assigning train and test datasets
train_normal = glob.glob('/content/Chest_XRay_Datasets/train/NORMAL/*.jpeg')
train_disease = glob.glob('/content/Chest_XRay_Datasets/train/PNEUMONIA/*.jpeg')

test_normal = glob.glob('/content/Chest_XRay_Datasets/test/NORMAL/*.jpeg')
test_disease = glob.glob('/content/Chest_XRay_Datasets/test/PNEUMONIA/*.jpeg')

train_paths = train_normal + train_disease
test_paths = test_normal + test_disease

#Labeling the Dataset
train_labels = [0] * len(train_normal) + [1] * len(train_disease)
test_labels = [0] * len(test_normal) + [1] * len(test_disease)

print(len(train_paths), len(train_labels))
print(len(test_paths), len(test_labels))

# Split and Check Random Images

train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, stratify=train_labels, test_size=0.2)

def show_random_img(paths, labels):
  path_rand_norm = random.choice(paths)
  path_rand_anom = random.choice(paths)
  fig = plt.figure(figsize=(10,10))

  ax1 = plt.subplot(1,2,1)
  img_rand_norm = Image.open(path_rand_norm).convert('LA')
  ax1.imshow(img_rand_norm)
  ax1.set_title('Normal X-ray')

  ax2 = plt.subplot(1,2,2)
  img_rand_anom = Image.open(path_rand_anom).convert('LA')
  ax2.imshow(img_rand_anom)
  ax2.set_title('Disease X-ray')

show_random_img(train_paths, train_labels)

# Define class from pytorch to load data from folder
class XrayDataset(Dataset):
  def __init__(self, paths, labels, transform=None):
    self.paths = paths
    self.labels = labels
    self.transform = transform

  def __len__(self):
    return len(self.paths)

  def __getitem__(self, idx):
    path = self.paths[idx]
    image = Image.open(path).convert('RGB')

    if self.transform:
      image = self.transform(image)

    label = self.labels[idx]
    label = torch.tensor(label)

    return image, label


train_dataset = XrayDataset(train_paths, train_labels)
next(iter(train_dataset))

# Used to check the Model Architecture
mobile = mobilenet_v2()
mobile

# Define the Model
class DiseaseClassifier(nn.Module):
    def __init__(self, pretrained=True):
      super(DiseaseClassifier, self).__init__()
      self.backbone = mobilenet_v2(pretrained=pretrained)
      self.features = nn.Sequential(*list(self.backbone.children())[:-1])
      self.conv = nn.Conv2d(in_channels=1280, out_channels=1, kernel_size=1)
      self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
      self.fc = nn.Linear(in_features=1, out_features=1, bias=False)
      # self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.features(x)
        x = self.conv(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

# Preprocessing pipeline
image_size = (224, 224)

train_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize(image_size),
    transforms.RandomRotation(degrees=15),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize(image_size),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_dataset = XrayDataset(train_paths, train_labels, transform=train_transform)
valid_dataset = XrayDataset(val_paths, val_labels, transform=train_transform)

# Training Pipeline
pretained = True
model = DiseaseClassifier(pretrained=pretained)
num_epochs = 20
train_batch_size = 16
val_batch_size = 16
criterion = nn.BCEWithLogitsLoss()
optimizer = Adam(model.parameters(), lr=0.001)

# Load datasets
train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size,  num_workers=2, shuffle=True)
val_dataloader = DataLoader(valid_dataset, batch_size=val_batch_size, num_workers=2, shuffle=False)

DataLoaders = {
    'train': train_dataloader,
    'val': val_dataloader
}

logging_steps = {
    'train': len(DataLoaders['train']) // 10,
    'val': len(DataLoaders['val']) // 10
}

dataset_sizes = {
    'train': len(train_dataset),
    'val': len(valid_dataset)
}

batch_size = {
    'train': train_batch_size,
    'val': val_batch_size
}

model.cuda()

# ! nvidia-smi

def train_model(model, criterion, optimizer, num_epochs, device='cuda'):
  since = time.time()
  best_model_wts = copy.deepcopy(model.state_dict())
  best_acc = 0.0

  for epoch in tqdm(range(num_epochs), leave=False):
    for phase in ['train', 'val']:
      if phase == 'train':
        model.train()
      else:
        model.eval()

      running_loss = 0.0
      running_corrects = 0

      for i, (inputs, labels) in tqdm(enumerate(DataLoaders[phase]),
                                      leave=False,
                                      total=len(DataLoaders[phase])):
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        with torch.set_grad_enabled(phase == 'train'):
          outputs = model(inputs)
          preds = outputs.sigmoid() > 0.5
          loss = criterion(outputs, labels.unsqueeze(1).float())

          if phase == 'train':
            loss.backward()
            optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

        if (i % logging_steps[phase] == 0) & (i > 0):
          epoch_loss = running_loss / ((i+1) * batch_size[phase])
          epoch_acc = running_corrects / ((i+1) * batch_size[phase])

          print(f'[{phase}]: {epoch+1}/{num_epochs} | Loss: {epoch_loss} | Acc: {epoch_acc}')

      epoch_loss = running_loss / dataset_sizes[phase]
      epoch_acc = running_corrects.double() / dataset_sizes[phase]

      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

      if phase == 'val' and epoch_acc > best_acc:
        best_acc = epoch_acc
        best_model_wts = copy.deepcopy(model.state_dict())

  time_elapsed = time.time() - since
  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
  print('Best val Acc: {:4f}'.format(best_acc))

  model.load_state_dict(best_model_wts)
  return model

model = train_model(model, criterion, optimizer, num_epochs, device)

# Save the best model weights to a file
model_path = "/content/best_model.pth"
torch.save(model.state_dict(), model_path)
print(f"Model saved to {model_path}")

# Testing the Model on test dataset
test_paths = glob.glob('/content/Chest_XRay_Datasets/test/NORMAL/*') + glob.glob('/content/Chest_XRay_Datasets/test/PNEUMONIA/*')
test_labels = [0] * len(glob.glob('/content/Chest_XRay_Datasets/test/NORMAL/*')) + [1] * len(glob.glob('/content/Chest_XRay_Datasets/test/PNEUMONIA/*'))
len(test_paths), len(test_labels)

test_dataset = XrayDataset(test_paths, test_labels, transform=train_transform)
test_dataloader = DataLoader(test_dataset, batch_size=16, num_workers=2, shuffle=False, drop_last=False)

y_pred = []
y_true = []

for i, (tensors, labels) in tqdm(enumerate(test_dataloader), leave=False, total=len(test_dataloader)):
  with torch.no_grad():
    predictions = model(tensors.cuda())
    predictions = predictions.sigmoid()
    predictions = predictions > 0.5
    y_pred.append(predictions)
    y_true.append(labels)

# Reshaping the y_pred and y_true vector for eval
y_pred = torch.cat(y_pred).cpu().numpy()
y_true = torch.cat(y_true).cpu().numpy()
y_pred = y_pred.astype(int)
y_true = y_true.astype(int)
y_pred = y_pred.reshape(-1)
y_true = y_true.reshape(-1)
print(y_pred.shape, y_true.shape)
# model.eval()

# Evaluation metrics and plots
from sklearn.metrics import (accuracy_score, recall_score, f1_score,  roc_curve,
                             auc,confusion_matrix)
import pandas as pd
import matplotlib.pyplot as plt

acc = accuracy_score(y_true, y_pred)
rec = recall_score(y_true, y_pred)
f1  = f1_score(y_true, y_pred)

df_metrics = pd.DataFrame({
    "metric": ["accuracy", "recall", "f1_score"],
    "value":  [acc, rec, f1]
})
print(df_metrics)


# ROC Curve
fpr, tpr, _ = roc_curve(y_true, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.2f})")
plt.plot([0,1], [0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic")
plt.legend(loc="lower right")
plt.show()

# Confusion Matrix
# First get your binary predictions
y_pred = (y_pred >= 0.5).astype(int)
cm = confusion_matrix(y_true, y_pred)

fig, ax = plt.subplots(figsize=(4,4))
im = ax.imshow(cm, interpolation='nearest')
ax.figure.colorbar(im, ax=ax)
classes = ['Normal','Disease']
ax.set(
    xticks=np.arange(len(classes)),
    yticks=np.arange(len(classes)),
    xticklabels=classes, yticklabels=classes,
    ylabel='True label',
    xlabel='Predicted label',
    title='Confusion Matrix'
)
# Loop over data dimensions and create text annotations.
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j, i, format(cm[i, j], 'd'),
                ha="center", va="center",
                color="white" if cm[i, j] > thresh else "black")
plt.tight_layout()
plt.show()